{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment2_code.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ie44hOchF3H3"
      },
      "source": [
        "# libriaries used are loaded\n",
        "\n",
        "from google.colab import drive\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, Dropout, Input\n",
        "\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWy4uccLF4qL",
        "outputId": "730a50c9-fd7c-4a31-d14e-a14704d1a186"
      },
      "source": [
        "def load_data(folder_in):\n",
        "    drive.mount('/content/drive')\n",
        "    folder = \"/content/drive/My Drive/CISC873_Assignments/\"+folder_in\n",
        "  \n",
        "\n",
        "    images = []\n",
        "    # lists all files in the folder directory\n",
        "    for file in os.listdir(folder):\n",
        "        # saves file id without the 'png' part\n",
        "        file_id = file.replace('.png', '')\n",
        "        # open an image file when the path is made from os.path.join\n",
        "        image = Image.open(\n",
        "            os.path.join(folder, file)\n",
        "            #image is converted to 'LA' and resizes the image\n",
        "        ).convert('LA').resize((200, 200))\n",
        "        # create numpy array of image\n",
        "        arr = np.array(image)\n",
        "        images.append(\n",
        "            (int(file_id), arr)\n",
        "        )\n",
        "    # sorts images ascending and creates a callable anaonymous function which \n",
        "    #set in the following set of instructions that points .sort at thost elements \n",
        "    #in which they should be sorted by\n",
        "    images.sort(key=lambda i: i[0])\n",
        "    return np.array([v for _id, v in images])\n",
        "\n",
        "\n",
        "\n",
        "x_train = load_data('train')\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "y_train = pd.read_csv(\"/content/drive/My Drive/CISC873_Assignments/y_train.csv\")['infection']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qNNL754JlJW"
      },
      "source": [
        "Fully Connected NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGuSYLhvGFJy"
      },
      "source": [
        "# fully connected neural network \n",
        "def build():\n",
        "  # this is the reshape layer or 'inpt' layer and converts input data for layers\n",
        "  # below. Here images are 256 * 256 * 2 (3D) pixels\n",
        "    img_in = Input(shape=(200, 200, 2))\n",
        "    # converts data into a 1D array for inputting into the next layer to create\n",
        "    # a single long feature vector\n",
        "    flattened = Flatten()(img_in)\n",
        "    # creates a dense layer. A dense layer feeds all outputs from previous layer\n",
        "    # to all its neurons. \n",
        "    fc1 = Dense(32)(flattened)\n",
        "    # adds dropout layer to avoid overfitting\n",
        "    fc1 = Dropout(0.3)(fc1)\n",
        "    # another dense layer\n",
        "    fc2 = Dense(64)(fc1)\n",
        "    fc3 = Dense(128)(fc2)\n",
        "    # adds dropout layer to avoid overfitting\n",
        "    #fc2 = Dropout(0.3)(fc2)\n",
        "    # used to determine the output of a neural network. Here we are using a sigmoid\n",
        "    # function (exists between 0 and 1). \n",
        "    output = Dense(1, activation = 'sigmoid')(fc3)\n",
        "    # Model groups layers into an object with training and inference features\n",
        "    model = tf.keras.Model(inputs=img_in, outputs=output)\n",
        "    return model\n",
        "\n",
        "# generates composite action coontaining all actions so far\n",
        "model = build()\n",
        "# configures model with losses and metrics with .compile\n",
        "model.compile(\n",
        "    # specifies the optimizer algorithm that is going to be used. Ada is a stochastic\n",
        "    # gradient descent method that is based on adaptive estimation of the first order and\n",
        "    # second order moments. \n",
        "        #optimizer=tf.keras.optimizers.RMSprop(),\n",
        "        #optimizer=tf.keras.optimizers.Adagrad(),\n",
        "        optimizer=tf.keras.optimizers.Adam(),\n",
        "        # implements a loss function to compute the quantity that a model should seek\n",
        "        # to minimize during training. 'binary_crossentropy' computes the cross-entropy\n",
        "        # loss between labels and predicted labels. \n",
        "        loss='binary_crossentropy',\n",
        "        # judges performance of model using 'BinaryAccuracy' which calculates how often\n",
        "        # predictions match binary labels. \n",
        "        metrics=['BinaryAccuracy', 'AUC']\n",
        "        )\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n10QfcaMJn7G"
      },
      "source": [
        "Convolutional NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hH5l10VBZ9v"
      },
      "source": [
        "# CNN MODEL 1\n",
        "\n",
        "def build():\n",
        "    img_in = Input(shape=(256, 256, 2))\n",
        "    # first convolution layer\n",
        "    fc0 = Conv2D(filters = 8, kernel_size = (3, 3), activation='relu')(img_in)\n",
        "    # batch normalization to standardize input\n",
        "    fc1 = BatchNormalization()(fc0)\n",
        "    # Max pooling yaer to downsample\n",
        "    fc2 = MaxPool2D(strides=(2,2))(fc1)\n",
        "    # flattening the array of pixels\n",
        "    fc3 = Flatten()(fc2)\n",
        "    # adding a dense layer to feed all outputs from the prevsiou later to all its neurons\n",
        "    fc4 = Dense(64)(fc3)\n",
        "\n",
        "    output = Dense(1, activation = 'sigmoid')(fc4)\n",
        "    model = tf.keras.Model(inputs=img_in, outputs=output)\n",
        "    return model\n",
        "\n",
        "\n",
        "model = build()\n",
        "model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['BinaryAccuracy', 'AUC']\n",
        "        )\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjBrctf8P6lx"
      },
      "source": [
        "# CNN MODEL 2\n",
        "\n",
        "def build():\n",
        "    img_in = Input(shape=(256, 256, 2))\n",
        "    fc0 = Conv2D(filters = 16, kernel_size = (3, 3))(img_in)\n",
        "    fc1 = BatchNormalization()(fc0)\n",
        "    fc2 = Conv2D(filters = 8, kernel_size = (3, 3))(fc1)\n",
        "    fc3 = MaxPool2D(strides=(2,2))(fc2)\n",
        "    fc4 = Flatten()(fc3)\n",
        "    fc5 = Dense(64)(fc4)\n",
        "    fc6 = Dense(32)(fc5)\n",
        "\n",
        "    output = Dense(1, activation = 'sigmoid')(fc6)\n",
        "    model = tf.keras.Model(inputs=img_in, outputs=output)\n",
        "    return model\n",
        "\n",
        "\n",
        "model = build()\n",
        "model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['BinaryAccuracy', 'AUC']\n",
        "        )\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vP_a8uAd8M90"
      },
      "source": [
        "# CNN MODEL 3 (best performing model)\n",
        "def build():\n",
        "    img_in = Input(shape=(200, 200, 2))\n",
        "    fc0 = Conv2D(filters = 32, kernel_size = (3, 3))(img_in)\n",
        "    fc1 = MaxPool2D(strides=(2,2))(fc0)\n",
        "    fc2 = Conv2D(filters = 64, kernel_size = (3, 3))(fc1)\n",
        "    fc3 = MaxPool2D(strides=(2,2))(fc2)\n",
        "\n",
        "\n",
        "\n",
        "    flattened = Flatten()(fc2)\n",
        "    fc4 = Dense(64)(flattened)\n",
        "    fc5 = Dropout(0.5)(fc4)\n",
        "\n",
        "\n",
        "    output = Dense(1, activation = 'sigmoid')(fc5)\n",
        "    model = tf.keras.Model(inputs=img_in, outputs=output)\n",
        "    return model\n",
        "\n",
        "\n",
        "model = build()\n",
        "model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['BinaryAccuracy', 'AUC']\n",
        "        )\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOT0ZmBDGFv2"
      },
      "source": [
        "# fitting model\n",
        "epochs = 40\n",
        "# defines number of samples to work through before updating the internal model parameters. \n",
        "batch_size = 70\n",
        "# training takes place when fit() is called, it takes training and validation data\n",
        "# and we specify a certain number of epochs we're training for.\n",
        "history = model.fit(x = x_train.reshape(487,200,200,2),\n",
        "                    y = y_train,\n",
        "                    batch_size = batch_size,\n",
        "                    validation_split=0.2,\n",
        "                    epochs=epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vEaJKtXrhfy",
        "outputId": "0b57acf5-d9e1-4c8f-ec94-b710fe0d8d22"
      },
      "source": [
        "x_test = load_data('test')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwzYYsXmGI9A"
      },
      "source": [
        "y_test = model.predict(x_test)\n",
        "\n",
        "y_test_df = pd.DataFrame()\n",
        "y_test_df['id'] = np.arange(len(y_test))\n",
        "y_test_df['infection'] = y_test.astype(int)\n",
        "y_test_df.to_csv('insert_new_name.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}